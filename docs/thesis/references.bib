@INPROCEEDINGS{beit3,
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and Wei, Furu},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Image as a Foreign Language: BEIT Pretraining for Vision and Vision-Language Tasks}, 
  year={2023},
  volume={},
  number={},
  pages={19175-19186},
  keywords={Visualization;Semantic segmentation;Computer architecture;Object detection;Transformers;Question answering (information retrieval);Pattern recognition;Vision;language;reasoning},
  doi={10.1109/CVPR52729.2023.01838}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle={Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event},
  volume={139},
  series={Proceedings of Machine Learning Research},
  pages={8748--8763},
  publisher={PMLR},
  year={2021},
  editor={Meila, Marina and Zhang, Tong},
}

@article{flava,
  title={FLAVA: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  journal={CoRR},
  volume={abs/2112.04482},
  year={2021},
  url={https://arxiv.org/abs/2112.04482}
}

@inproceedings{visual_n_grams,
  title={Learning visual n-grams from web data},
  author={Li, A. and Jabri, A. and Joulin, A. and van der Maaten, L.},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4183--4192},
  year={2017}
}

@inproceedings{sst2,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D13-1170",
    pages = "1631--1642",
}

@article{cola,
    title={Neural Network Acceptability Judgments},
    author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1805.12471},
    year={2018}
}

@InProceedings{stsb,
title = {Machine translated multilingual STS benchmark dataset.},
author={Philip May},
year={2021},
url={https://github.com/PhilipMay/stsb-multi-mt}
}

@inproceedings{mrpc,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, William B and Brockett, Chris},
  booktitle={Proceedings of the International Workshop on Paraphrasing},
  year={2005}
}

@inproceedings{squad,
  author = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  title = {{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text},
  booktitle = {Proceedings of EMNLP},
  year = {2016},
  publisher = {Association for Computational Linguistics},
  pages = {2383--2392},
  location = {Austin, Texas},
}

@inproceedings{glue,
  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  note={In the Proceedings of ICLR.},
  year={2019}
}

@incollection{rte1,
  title={The {PASCAL} recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment},
  pages={177--190},
  year={2006},
  publisher={Springer}
}
@article{rte2,
  title={The second {PASCAL} recognising textual entailment challenge},
  author={Bar Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},
  year={2006}
}
@inproceedings{rte3,
  title={The third {PASCAL} recognizing textual entailment challenge},
  author={Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, Bill},
  booktitle={Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing},
  pages={1--9},
  year={2007},
  organization={Association for Computational Linguistics},
}
@article{rte5,
  title={The Fifth {PASCAL} Recognizing Textual Entailment Challenge},
  author={Bentivogli, Luisa and Dagan, Ido and Dang, Hoa Trang and Giampiccolo, Danilo and Magnini, Bernardo},
  booktitle={TAC},
  year={2009}
}

@inproceedings{mnli,
  author    = {Williams, Adina and Nangia, Nikita and Bowman, Samuel R.},
  title = {A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  booktitle = {Proceedings of NAACL-HLT},
  year = {2018}
}

@article{shre,
  title={See, Hear, and Read: Deep Aligned Representations},
  author={Aytar, Yusuf and Vondrick, Carl and Torralba, Antonio},
  journal={arXiv preprint arXiv:1706.00932},
  year={2017},
  url={https://arxiv.org/abs/1706.00932}
}

@inproceedings{karpathy_split,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015},
  pages={3128--3137},
  year={2015},
  organization={IEEE Computer Society},
  publisher={IEEE}
}

@INPROCEEDINGS{memory_bank,
  author={Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X. and Lin, Dahua},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Unsupervised Feature Learning via Non-parametric Instance Discrimination}, 
  year={2018},
  volume={},
  number={},
  pages={3733-3742},
  keywords={Measurement;Task analysis;Training;Neural networks;Supervised learning;Testing;Visualization},
  doi={10.1109/CVPR.2018.00393}}

@inproceedings{coco,
  author    = {Tsung-Yi Lin and Michael Maire and Serge J. Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'a}r and C. Lawrence Zitnick},
  title     = {Microsoft {COCO}: Common Objects in Context},
  booktitle = {Computer Vision - {ECCV} 2014 - 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part {V}},
  editor    = {David J. Fleet and Tom{\'a}s Pajdla and Bernt Schiele and Tinne Tuytelaars},
  series    = {Lecture Notes in Computer Science},
  volume    = {8693},
  pages     = {740--755},
  publisher = {Springer},
  year      = {2014},
}

@inproceedings{vlmo,
      title={{VLMo}: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts},
      author={Hangbo Bao and Wenhui Wang and Li Dong and Qiang Liu and Owais Khan Mohammed and Kriti Aggarwal and Subhojit Som and Songhao Piao and Furu Wei},
      booktitle={Advances in Neural Information Processing Systems},
      year={2022},
      url={https://openreview.net/forum?id=bydKs84JEyw}
}

@article{flickr30k,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  month={Feb}
}

@inproceedings{sbu,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara L.},
  booktitle={Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011. Proceedings of a meeting held 12-14 December 2011, Granada, Spain},
  editor={Shawe-Taylor, John and Zemel, Richard S. and Bartlett, Peter L. and Pereira, Fernando C. N. and Weinberger, Kilian Q.},
  pages={1143--1151},
  year={2011}
}

@inproceedings{cc3m,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers},
  editor={Gurevych, Iryna and Miyao, Yusuke},
  pages={2556--2565},
  year={2018},
  organization={Association for Computational Linguistics}
}

@article{vg,
author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and Fei-Fei, Li},
title = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
year = {2017},
issue_date = {May       2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {123},
number = {1},
issn = {0920-5691},
journal = {Int. J. Comput. Vision},
month = {may},
pages = {32--73},
numpages = {42},
keywords = {Scene graph, Relationships, Question answering, Objects, Language, Knowledge, Image, Dataset, Crowdsourcing, Computer vision, Attributes}
}

@inproceedings{transformer, 
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
title = {Attention is all you need}, 
year = {2017}, 
isbn = {9781510860964}, 
publisher = {Curran Associates Inc.}, 
address = {Red Hook, NY, USA}, 
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems}, 
pages = {6000–-6010}, 
numpages = {11}, 
location = {Long Beach, California, USA}, 
series = {NIPS'17} }

@misc{llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron et al},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{kd,
      title={Distilling the Knowledge in a Neural Network}, 
      author={Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
      year={2015},
      eprint={1503.02531},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1503.02531}, 
}

@article{kd_survey,
  title={Knowledge Distillation: A Survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J. and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer},
  doi={10.1007/s11263-021-01453-z},
  url={https://doi.org/10.1007/s11263-021-01453-z},
  issn={1573-1405}
}

@inproceedings{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  booktitle={NeurIPS EMC^2 Workshop},
  year={2019}
}

@article{imagenet,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}

@article{vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
}

@article{moe,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{moe_switch_transformer,
  author = {Fedus, William and Zoph, Barret and Shazeer, Noam}, 
  title = {Switch transformers: scaling to trillion parameter models with simple and efficient sparsity}, 
  year = {2022}, 
  issue_date = {January 2022}, 
  publisher = {JMLR.org}, 
  volume = {23}, 
  number = {1}, 
  issn = {1532-4435}, 
  abstract = {In deep learning, models typically reuse the same parameters for all inputs. Mixture of Experts (MoE) models defy this and instead select different parameters for each incoming example. The result is a sparsely-activated model--with an outrageous number of parameters--but a constant computational cost. However, despite several notable successes of MoE, widespread adoption has been hindered by complexity, communication costs, and training instability. We address these with the introduction of the Switch Transformer. We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and computational costs. Our proposed training techniques mitigate the instabilities, and we show large sparse models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off T5-Base and T5-Large (Raffel et al., 2019) to obtain up to 7x increases in pre-training speed with the same computational resources. These improvements extend into multilingual settings where we measure gains over the mT5-Base version across all 101 languages. Finally, we advance the current scale of language models by pre-training up to trillion parameter models on the "Colossal Clean Crawled Corpus", and achieve a 4x speedup over the T5-XXL model.},
  journal = {J. Mach. Learn. Res.},
  month = {jan},
  articleno = {120},
  numpages = {39},
  keywords = {mixture-of-experts, natural language processing, sparsity, large-scale machine learning, distributed computing}
}
