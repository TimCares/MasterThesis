= Appendix
== Hyperparameters <hyperparameters>

#figure(
  table(
    table.vline(x:1, stroke: .3pt),
    table.vline(x:2, stroke: .3pt),
    columns: 3,
    stroke: none,
    table.hline(),
    table.header(
      [*Type*],
      [*Hyperparameters*],
      [*Values*],
    ),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 6, align:horizon, [*Model*]), 
    [Layers], [6],
    [Hidden size], [768],
    [FFN inner hidden size], [3072],
    [Attention Heads], [12],
    [Patch size], [16$times$16],
    [Input resolution], [224$times$224],
    table.hline(stroke: .6pt),
    table.cell(rowspan: 11, align:horizon, [*Training*]), 
    [Epochs], [10],
    [Total steps], [50040],
    [Batch size], [256],
    [Optimizer], [AdamW],
    [AdamW $epsilon$], [1e-06],
    [AdamW $beta$], [(0.9,0.98)],
    [Weight decay], [0.01],
    [Base learning rate], [1e-4],
    [Learning rate schedule], [Cosine],
    [Warmup steps], [5004 (10% of total steps)],
    [Hardware], [1 $times$ RTX 4090 24GB],
    table.hline(stroke: .6pt),
    table.cell(rowspan: 2, align:horizon, [*Augmentations*]), 
    [Horizontal flipping prob.], [0.5],
    [RandomResizeCrop range], [[0.08, 1.0]],
    table.hline(),
  ),
  caption: [Hyperparameters used for distilling a Data2Vec2 image model.
  ],
)<distil_data2vec2_hyperparameters>


#show table: set text(8pt)
#figure(
  table(
    table.vline(x:1, stroke: .3pt),
    table.vline(x:2, stroke: .3pt),
    columns: (auto, auto, auto, auto, auto, auto, auto, auto),
    stroke: none,
    table.hline(),
    table.header(
      table.cell(rowspan: 2, align:horizon, [*Type*]),
      table.cell(rowspan: 2, align:horizon, [*Hyperparameters*]),
      table.cell(colspan: 2, align:horizon, [*ImageNet*]),
      table.cell(colspan: 2, align:horizon, [*CIFAR10*]),
      table.cell(colspan: 2, align:horizon, [*CIFAR100*]),
      [Finetune], table.vline(stroke: .3pt), [Linear probe],table.vline(stroke: .3pt), 
      [Finetune], table.vline(stroke: .3pt), [Linear probe],table.vline(stroke: .3pt), 
      [Finetune], table.vline(stroke: .3pt), [Linear probe],
    ),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 11, align:horizon, [*Training*]), 
    [Epochs], table.cell(colspan: 6, align:horizon, [15]),
    [Batch size], table.cell(colspan: 6, align:horizon, [256]),
    [Optimizer], table.cell(colspan: 6, align:horizon, [AdamW]),
    [AdamW $epsilon$], table.cell(colspan: 6, align:horizon, [1e-8]),
    [AdamW $beta$], table.cell(colspan: 6, align:horizon, [(0.9, 0.999)]),
    [Weight decay], table.cell(colspan: 6, align:horizon, [0.01]),
    [Base learning rate], table.cell(colspan: 6, align:horizon, [1e-3]),
    [Layer Decay], table.cell(colspan: 6, align:horizon, [0.81]),
    [Learning rate schedule], table.cell(colspan: 6, align:horizon, [Cosine]),
    [Warmup steps], table.cell(colspan: 6, align:horizon, [10% of total steps]),
    [Hardware], table.cell(colspan: 6, align:horizon, [1 $times$ RTX 4090 24GB]),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 5, align:horizon, [*Mixup* @mixup*\/Cutmix* @cutmix]),
    [Mixup prob.], table.cell(colspan: 6, align:horizon, [0.8]),
    [Cutmix prob.], table.cell(colspan: 6, align:horizon, [1.0]),
    [Prob.], table.cell(colspan: 6, align:horizon, [0.9]),
    [Switch prob.], table.cell(colspan: 6, align:horizon, [0.5]),
    [Label smooting], table.cell(colspan: 6, align:horizon, [0.1]),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 4, align:horizon, [*RandAugment* @randaugment]),
    [Magintude], table.cell(colspan: 6, align:horizon, [9]),
    [Magnitude std.], table.cell(colspan: 6, align:horizon, [0.5]),
    [Magnitude inc.], table.cell(colspan: 6, align:horizon, [1]),
    [\# ops], table.cell(colspan: 6, align:horizon, [2]),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 3, align:horizon, [*RandomErase* @randerase]),
    [Prob.], table.cell(colspan: 6, align:horizon, [0.25]),
    [Mode], table.cell(colspan: 6, align:horizon, [pixel]),
    [\# erase], table.cell(colspan: 6, align:horizon, [1]),
    table.hline(),
  ),
  caption: [Hyperparameters used for the ImageNet-1K @imagenet, CIFAR10 @cifar_10_100, and CIFAR100 @cifar_10_100 of the distilled Data2Vec2 image model.
  We refer to the respective papers for details on the augmentation techniques @mixup @cutmix @randaugment @randerase.
  ],
)<distil_data2vec2_imagenet_finetuning_hyperparameters>
#show table: set text(12pt)

#show table: set text(8pt)
#figure(
  table(
    table.vline(x:1, stroke: .3pt),
    table.vline(x:2, stroke: .3pt),
    columns: 10,
    stroke: none,
    table.hline(),
    table.header(
      [*Type*],
      [*Hyperparameters*],
      [*MNLI*],
      [*QNLI*],
      [*RTE*],
      [*MRPC*],
      [*QQP*],
      [*STS-B*],
      [*CoLA*],
      [*SST*],
    ),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 12, align:horizon, [*Training*]), 
    [Epochs], table.cell(colspan: 8, align:horizon, [15]),
    [Batch size], table.cell(colspan: 8, align:horizon, [256]),
    [Optimizer], table.cell(colspan: 8, align:horizon, [AdamW]),
    [AdamW $epsilon$], table.cell(colspan: 8, align:horizon, [1e-8]),
    [AdamW $beta$], table.cell(colspan: 8, align:horizon, [(0.9, 0.999)]),
    [Weight decay], table.cell(colspan: 8, align:horizon, [0.01]),
    [Base learning rate], table.cell(colspan: 8, align:horizon, [1e-3]),
    [Layer Decay], table.cell(colspan: 8, align:horizon, [0.81]),
    [Learning rate schedule], table.cell(colspan: 8, align:horizon, [Cosine]),
    [Warmup steps], table.cell(colspan: 8, align:horizon, [10% of total steps]),
    [Metric], [Accuracy], [Accuracy], [Accuracy], [F1], [F1], [Spearman], [Accuracy], [Accuracy],
    [Hardware], table.cell(colspan: 8, align:horizon, [1 $times$ RTX 4090 24GB]),
    table.hline(),
  ),
  caption: [Hyperparameters for the GLUE @glue benchmark tasks of the distilled Data2Vec2 image model.
  ],
)<distil_data2vec2_glue_finetuning_hyperparameters>
#show table: set text(12pt)

#figure(
  table(
    table.vline(x:1, stroke: .3pt),
    table.vline(x:2, stroke: .3pt),
    columns: 3,
    stroke: none,
    table.hline(),
    table.header(
      [*Type*],
      [*Hyperparameters*],
      [*Values*],
    ),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 8, align:horizon, [*Model*]), 
    [Image/Text layers], [6 (Transformer)],
    [Shared layers], [3 (MLP)],
    [Hidden size], [768],
    [FFN inner hidden size], [3072],
    [Attention Heads], [12],
    [Patch size], [16$times$16],
    [Input resolution], [224$times$224],
    [Max. caption length], [64],
    table.hline(stroke: .6pt),
    table.cell(rowspan: 11, align:horizon, [*Training*]), 
    [Epochs], [7],
    [Total steps], [89273],
    [Batch size], [256],
    [Optimizer], [AdamW],
    [AdamW $epsilon$], [1e-06],
    [AdamW $beta$], [(0.9,0.98)],
    [Weight decay], [0.01],
    [Base learning rate], [1e-4],
    [Learning rate schedule], [Cosine],
    [Warmup steps], [8927 (10% of total steps)],
    [Hardware], [1 $times$ RTX 4090 24GB],
    table.hline(stroke: .6pt),
    table.cell(rowspan: 2, align:horizon, [*Augmentations*]), 
    [Horizontal flipping prob.], [0.5],
    [RandomResizeCrop range], [[0.9, 1.0]],
    table.hline(),
  ),
  caption: [Hyperparameters used for training the Transformer SHRe model.
  ],
)<transformer_shre_hyperparams>

#figure(
  table(
    table.vline(x:1, stroke: .3pt),
    table.vline(x:2, stroke: .3pt),
    columns: 3,
    stroke: none,
    table.hline(),
    table.header(
      [*Type*],
      [*Hyperparameters*],
      [*Values*],
    ),
    table.hline(stroke: .6pt),
    table.cell(rowspan: 6, align:horizon, [*Model*]), 
    [Encoder], [BEiTv2 ViT-B/16],
    [\# Decoder layers], [1],
    [Codebook size], [{1024$times$16, 8192$times$16}],
    [Patch size], [16$times$16],
    [EMA decay], [0.99],
    [Mask prob.], [0.9],
    table.hline(stroke: .6pt),
    table.cell(rowspan: 11, align:horizon, [*Training*]), 
    [Epochs], [10],
    [Total steps], [50040],
    [Batch size], [256],
    [Optimizer], [AdamW],
    [AdamW $epsilon$], [1e-06],
    [AdamW $beta$], [(0.9,0.98)],
    [Weight decay], [0.01],
    [Base learning rate], [1e-3],
    [Learning rate schedule], [Cosine],
    [Warmup steps], [5004 (10% of total steps)],
    [Hardware], [2 $times$ RTX 4090 24GB],
    table.hline(stroke: .6pt),
    table.cell(rowspan: 2, align:horizon, [*Augmentations*]), 
    [Horizontal flipping prob.], [0.5],
    [RandomResizeCrop range], [[0.5, 1.0]],
    table.hline(),
  ),
  caption: [Hyperparameters used for training the image vector quantizer.
  ],
)<image_vq_cls_hparams>