\documentclass[fontsize=12pt,paper=a4,twoside=semi,parskip=half-,headsepline,headinclude]{scrreprt}
% Grundgröße 12pt, zweiseitig
\usepackage[headsepline,automark]{scrlayer-scrpage}
% Seitenköpfe automatisch 
\usepackage[english]{babel}
% Sprachpaket für Deutsch (Umlaute, Trennung,deutsche Überschriften)
\usepackage{blindtext}
% macht nur den Blindtext, den Sie aktuell sehen
\usepackage{lmodern}
% schöne PDF-Schrift
\usepackage{graphicx,hyperref,amssymb}
%Graphikeinbindung, Hyperref (alles klickbar, Bookmarks),
%Math. Symbole aus AmsTeX
\usepackage[utf8]{inputenc}
% Umlaute und über Tastatur einzugeben
\usepackage{listings}
% nette Listing-Formatierung
\usepackage{xcolor}
\pagecolor{white}

\graphicspath{ {./images/} } 

% Festlegung Kopf- und Fußzeile     
\defpagestyle{meinstil}{%
{\headmark \hfill}
{\hfill \headmark}
{\hfill \headmark\hfill }
(\textwidth,.4pt)
}{%
(\textwidth,.4pt)
{\pagemark\hfill Tim Cares}
{\today \hfill \pagemark}
{\today\hfill\pagemark} 
}
\pagestyle{meinstil} 

\raggedbottom
\renewcommand{\topfraction}{1}
\renewcommand{\bottomfraction}{1}

 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}    % hier gehts los
  \thispagestyle{empty} % Titelseite
\includegraphics[width=0.2\textwidth]{Wortmarke_WI_schwarz}

   {  ~ \sffamily
  \vfill
  {\Huge\bfseries Exposé}
  \bigskip

  {\Large 
  Tim Cares \\[2ex]
  Exposé for a Master-Thesis for the degree `Master Angewandte Informatik' 
 \\[5ex]
   \today } 
}
 \vfill
  
  ~ \hfill
  \includegraphics[height=0.3\paperheight]{H_WI_Pantone1665} 

\vspace*{-3cm}

  \newpage \thispagestyle{empty}
 \begin{tabular}{ll}
{\bfseries\sffamily Author} &  Tim Cares \\ 
            & 1717249 \\
            & tim.cares@stud.hs-hannover.de \\[5ex]
{\bfseries\sffamily First examiner:} & Prof. Dr. Volker Ahlers \\
          & Abteilung Informatik, Fakultät IV \\
         & Hochschule Hannover \\
        & volker.ahlers@hs-hannover.de \\[5ex]
\end{tabular}

\vfill

\vfill
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center} \sffamily\bfseries Statement of independence \end{center}
% fett und zentriert in der minipage

I hereby declare that I have written the submitted exposé
independently and without outside help, that I have not used any sources or aids
other than those specified by me and that I have content taken from other works marked as such.
\vspace*{7ex}

Hannover, \today \hfill Signature
  \pdfbookmark[0]{Inhalt}{contents}
  \tableofcontents  % Inhaltsverzeichnis

\include{./content.tex}
\begin{thebibliography}{00}
  \bibitem{geron} Aurelien Geron. Hands-On Machine Learning with Scikit-Learn, Keras, and Ten- sorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. O’Reilly Media, Inc., Sebastopol, 2 edition, 2019.
  \bibitem{lecun} Yann LeCun and Ishan Misra. Meta AI. (n.d.). Self-Supervised Learning: The Dark Matter of Intelligence. AI Meta Blog. Retrieved December 29, 2023, from https://ai.meta.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/
  \bibitem{wu} Z. Wu, Y. Xiong, S. X. Yu and D. Lin, "Unsupervised Feature Learning via Non-parametric Instance Discrimination," 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 2018, pp. 3733-3742, doi: 10.1109/CVPR.2018.00393.
  \bibitem{he} K. He, H. Fan, Y. Wu, S. Xie and R. Girshick, "Momentum Contrast for Unsupervised Visual Representation Learning," 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, WA, USA, 2020, pp. 9726-9735, doi: 10.1109/CVPR42600.2020.00975.
  \bibitem{chen} X. Chen and K. He, "Exploring Simple Siamese Representation Learning," 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, TN, USA, 2021, pp. 15745-15753, doi: 10.1109/CVPR46437.2021.01549.
  \bibitem{ling} LING, Shaoshi, et al. Deep contextualized acoustic representations for semi-supervised speech recognition. In: ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020. S. 6429-6433.
  \bibitem{wang} Wenhui Wang et al. Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp. 19175-19186
  \bibitem{baevski} Baevski, Alexei, et al. Data2vec: A general framework for self-supervised learning in speech, vision and language. In: International Conference on Machine Learning. PMLR, 2022. S. 1298-1312.
  \bibitem{bao} Bao, Hangbo, et al. Vlmo: Unified vision-language pre-training with mixture-of-modality-experts. Advances in Neural Information Processing Systems, 2022, 35. Jg., S. 32897-32912.
  \bibitem{singh} Singh, Amanpreet, et al. Flava: A foundational language and vision alignment model. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022. S. 15638-15650.
  \bibitem{vaswani} Vaswani, Ashish, et al. Attention is all you need. Advances in neural information processing systems, 2017, 30. Jg.
  \bibitem{dosovitskiy} Dosovitskiy, Alexey, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.
\end{thebibliography}

\end{document}


