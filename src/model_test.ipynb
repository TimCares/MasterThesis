{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('fairseq/')\n",
    "import torch\n",
    "from examples.data2vec.models.data2vec2 import Data2VecMultiModel\n",
    "from examples.data2vec.models.data2vec2 import Data2VecMultiConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('nlp_base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['args', 'cfg', 'model', 'criterion', 'optimizer_history', 'task_state', 'extra_state', 'last_optimizer_state'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_name': None,\n",
       " 'common': {'_name': None,\n",
       "  'no_progress_bar': False,\n",
       "  'log_interval': 200,\n",
       "  'log_format': 'json',\n",
       "  'log_file': None,\n",
       "  'aim_repo': None,\n",
       "  'aim_run_hash': None,\n",
       "  'tensorboard_logdir': 'tb',\n",
       "  'wandb_project': None,\n",
       "  'azureml_logging': False,\n",
       "  'seed': 1,\n",
       "  'cpu': False,\n",
       "  'tpu': False,\n",
       "  'bf16': False,\n",
       "  'memory_efficient_bf16': False,\n",
       "  'fp16': True,\n",
       "  'memory_efficient_fp16': False,\n",
       "  'fp16_no_flatten_grads': True,\n",
       "  'fp16_init_scale': 128,\n",
       "  'fp16_scale_window': None,\n",
       "  'fp16_scale_tolerance': 0.0,\n",
       "  'on_cpu_convert_precision': False,\n",
       "  'min_loss_scale': 0.0001,\n",
       "  'threshold_loss_scale': None,\n",
       "  'amp': False,\n",
       "  'amp_batch_retries': 2,\n",
       "  'amp_init_scale': 128,\n",
       "  'amp_scale_window': None,\n",
       "  'user_dir': '/data/home/wnhsu/fairseq_repos/fairseq-py-d2v-dev/examples/data2vec',\n",
       "  'empty_cache_freq': 0,\n",
       "  'all_gather_list_size': 16384,\n",
       "  'model_parallel_size': 1,\n",
       "  'quantization_config_path': None,\n",
       "  'profile': False,\n",
       "  'reset_logging': False,\n",
       "  'suppress_crashes': False,\n",
       "  'use_plasma_view': False,\n",
       "  'plasma_path': '/tmp/plasma'},\n",
       " 'common_eval': {'_name': None,\n",
       "  'path': None,\n",
       "  'post_process': None,\n",
       "  'quiet': False,\n",
       "  'model_overrides': '{}',\n",
       "  'results_path': None},\n",
       " 'distributed_training': {'_name': None,\n",
       "  'distributed_world_size': 16,\n",
       "  'distributed_num_procs': 1,\n",
       "  'distributed_rank': 0,\n",
       "  'distributed_backend': 'nccl',\n",
       "  'distributed_init_method': 'tcp://a100-st-p4d24xlarge-441:45481',\n",
       "  'distributed_port': 45481,\n",
       "  'device_id': 0,\n",
       "  'distributed_no_spawn': True,\n",
       "  'ddp_backend': 'legacy_ddp',\n",
       "  'ddp_comm_hook': 'none',\n",
       "  'bucket_cap_mb': 25,\n",
       "  'fix_batches_to_gpus': False,\n",
       "  'find_unused_parameters': False,\n",
       "  'gradient_as_bucket_view': False,\n",
       "  'fast_stat_sync': False,\n",
       "  'heartbeat_timeout': -1,\n",
       "  'broadcast_buffers': False,\n",
       "  'slowmo_momentum': None,\n",
       "  'slowmo_base_algorithm': 'localsgd',\n",
       "  'localsgd_frequency': 3,\n",
       "  'nprocs_per_node': 1,\n",
       "  'pipeline_model_parallel': False,\n",
       "  'pipeline_balance': None,\n",
       "  'pipeline_devices': None,\n",
       "  'pipeline_chunks': 0,\n",
       "  'pipeline_encoder_balance': None,\n",
       "  'pipeline_encoder_devices': None,\n",
       "  'pipeline_decoder_balance': None,\n",
       "  'pipeline_decoder_devices': None,\n",
       "  'pipeline_checkpoint': 'never',\n",
       "  'zero_sharding': 'none',\n",
       "  'fp16': True,\n",
       "  'memory_efficient_fp16': False,\n",
       "  'fsdp_mp': False,\n",
       "  'tpu': False,\n",
       "  'no_reshard_after_forward': False,\n",
       "  'fp32_reduce_scatter': False,\n",
       "  'cpu_offload': False,\n",
       "  'use_sharded_state': False,\n",
       "  'not_fsdp_flatten_parameters': False},\n",
       " 'dataset': {'_name': None,\n",
       "  'num_workers': 1,\n",
       "  'skip_invalid_size_inputs_valid_test': True,\n",
       "  'max_tokens': None,\n",
       "  'batch_size': 2,\n",
       "  'required_batch_size_multiple': 8,\n",
       "  'required_seq_len_multiple': 1,\n",
       "  'dataset_impl': None,\n",
       "  'data_buffer_size': 10,\n",
       "  'train_subset': 'train',\n",
       "  'valid_subset': 'valid',\n",
       "  'combine_valid_subsets': None,\n",
       "  'ignore_unused_valid_subsets': True,\n",
       "  'validate_interval': 1,\n",
       "  'validate_interval_updates': 0,\n",
       "  'validate_after_updates': 0,\n",
       "  'fixed_validation_seed': None,\n",
       "  'disable_validation': True,\n",
       "  'max_tokens_valid': None,\n",
       "  'batch_size_valid': 2,\n",
       "  'max_valid_steps': None,\n",
       "  'curriculum': 0,\n",
       "  'gen_subset': 'test',\n",
       "  'num_shards': 1,\n",
       "  'shard_id': 0,\n",
       "  'grouped_shuffling': False,\n",
       "  'update_epoch_batch_itr': False,\n",
       "  'update_ordered_indices_seed': False},\n",
       " 'optimization': {'_name': None,\n",
       "  'max_epoch': 0,\n",
       "  'max_update': 1000000,\n",
       "  'stop_time_hours': 0.0,\n",
       "  'clip_norm': 1.0,\n",
       "  'sentence_avg': False,\n",
       "  'update_freq': [1],\n",
       "  'lr': [0.0002],\n",
       "  'stop_min_lr': -1.0,\n",
       "  'use_bmuf': False,\n",
       "  'skip_remainder_batch': False,\n",
       "  'debug_param_names': False},\n",
       " 'checkpoint': {'_name': None,\n",
       "  'save_dir': 'checkpoints',\n",
       "  'restore_file': 'checkpoint_last.pt',\n",
       "  'continue_once': None,\n",
       "  'finetune_from_model': None,\n",
       "  'reset_dataloader': False,\n",
       "  'reset_lr_scheduler': False,\n",
       "  'reset_meters': False,\n",
       "  'reset_optimizer': False,\n",
       "  'optimizer_overrides': '{}',\n",
       "  'save_interval': 1,\n",
       "  'save_interval_updates': 50000,\n",
       "  'keep_interval_updates': 1,\n",
       "  'keep_interval_updates_pattern': -1,\n",
       "  'keep_last_epochs': -1,\n",
       "  'keep_best_checkpoints': -1,\n",
       "  'no_save': False,\n",
       "  'no_epoch_checkpoints': True,\n",
       "  'no_last_checkpoints': False,\n",
       "  'no_save_optimizer_state': False,\n",
       "  'best_checkpoint_metric': 'loss',\n",
       "  'maximize_best_checkpoint_metric': False,\n",
       "  'patience': -1,\n",
       "  'checkpoint_suffix': '',\n",
       "  'checkpoint_shard_count': 1,\n",
       "  'load_checkpoint_on_all_dp_ranks': False,\n",
       "  'write_checkpoints_asynchronously': False,\n",
       "  'model_parallel_size': 1},\n",
       " 'bmuf': {'_name': None,\n",
       "  'block_lr': 1.0,\n",
       "  'block_momentum': 0.875,\n",
       "  'global_sync_iter': 50,\n",
       "  'warmup_iterations': 500,\n",
       "  'use_nbm': False,\n",
       "  'average_sync': False,\n",
       "  'distributed_world_size': 16},\n",
       " 'generation': {'_name': None,\n",
       "  'beam': 5,\n",
       "  'nbest': 1,\n",
       "  'max_len_a': 0.0,\n",
       "  'max_len_b': 200,\n",
       "  'min_len': 1,\n",
       "  'match_source_len': False,\n",
       "  'unnormalized': False,\n",
       "  'no_early_stop': False,\n",
       "  'no_beamable_mm': False,\n",
       "  'lenpen': 1.0,\n",
       "  'unkpen': 0.0,\n",
       "  'replace_unk': None,\n",
       "  'sacrebleu': False,\n",
       "  'score_reference': False,\n",
       "  'prefix_size': 0,\n",
       "  'no_repeat_ngram_size': 0,\n",
       "  'sampling': False,\n",
       "  'sampling_topk': -1,\n",
       "  'sampling_topp': -1.0,\n",
       "  'constraints': None,\n",
       "  'temperature': 1.0,\n",
       "  'diverse_beam_groups': -1,\n",
       "  'diverse_beam_strength': 0.5,\n",
       "  'diversity_rate': -1.0,\n",
       "  'print_alignment': None,\n",
       "  'print_step': False,\n",
       "  'lm_path': None,\n",
       "  'lm_weight': 0.0,\n",
       "  'iter_decode_eos_penalty': 0.0,\n",
       "  'iter_decode_max_iter': 10,\n",
       "  'iter_decode_force_max_iter': False,\n",
       "  'iter_decode_with_beam': 1,\n",
       "  'iter_decode_with_external_reranker': False,\n",
       "  'retain_iter_history': False,\n",
       "  'retain_dropout': False,\n",
       "  'retain_dropout_modules': None,\n",
       "  'decoding_format': None,\n",
       "  'no_seed_provided': False,\n",
       "  'eos_token': None},\n",
       " 'eval_lm': {'_name': None,\n",
       "  'output_word_probs': False,\n",
       "  'output_word_stats': False,\n",
       "  'context_window': 0,\n",
       "  'softmax_batch': 9223372036854775807},\n",
       " 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'},\n",
       " 'model': {'_name': 'data2vec_multi',\n",
       "  'cosine_loss_temp': 0.0,\n",
       "  'loss_beta': 0.0,\n",
       "  'loss_scale': 1.0,\n",
       "  'mean_loss': False,\n",
       "  'reconstruct_all': False,\n",
       "  'depth': 12,\n",
       "  'start_drop_path_rate': 0.0,\n",
       "  'end_drop_path_rate': 0.0,\n",
       "  'num_heads': 12,\n",
       "  'norm_eps': 1e-05,\n",
       "  'norm_affine': True,\n",
       "  'encoder_dropout': 0.1,\n",
       "  'post_mlp_drop': 0.1,\n",
       "  'attention_dropout': 0.1,\n",
       "  'activation_dropout': 0.0,\n",
       "  'dropout_input': 0.0,\n",
       "  'layerdrop': 0.0,\n",
       "  'embed_dim': 768,\n",
       "  'mlp_ratio': 4.0,\n",
       "  'layer_norm_first': False,\n",
       "  'average_top_k_layers': 12,\n",
       "  'end_of_block_targets': False,\n",
       "  'clone_batch': 8,\n",
       "  'layer_norm_target_layer': False,\n",
       "  'batch_norm_target_layer': False,\n",
       "  'instance_norm_target_layer': True,\n",
       "  'instance_norm_targets': False,\n",
       "  'layer_norm_targets': False,\n",
       "  'ema_decay': 0.9999,\n",
       "  'ema_same_dtype': True,\n",
       "  'log_norms': True,\n",
       "  'ema_end_decay': 1.0,\n",
       "  'ema_anneal_end_step': 100000,\n",
       "  'ema_encoder_only': True,\n",
       "  'max_update': 1000000,\n",
       "  'modalities': {'audio': {'type': 'AUDIO',\n",
       "    'prenet_depth': 4,\n",
       "    'prenet_layerdrop': 0.0,\n",
       "    'prenet_dropout': 0.0,\n",
       "    'start_drop_path_rate': 0.0,\n",
       "    'end_drop_path_rate': 0.0,\n",
       "    'num_extra_tokens': 0,\n",
       "    'init_extra_token_zero': True,\n",
       "    'mask_noise_std': 0.01,\n",
       "    'mask_prob_min': None,\n",
       "    'mask_prob': 0.7,\n",
       "    'inverse_mask': False,\n",
       "    'mask_prob_adjust': 0.0,\n",
       "    'keep_masked_pct': 0.0,\n",
       "    'mask_length': 5,\n",
       "    'add_masks': False,\n",
       "    'remove_masks': False,\n",
       "    'mask_dropout': 0.0,\n",
       "    'encoder_zero_mask': True,\n",
       "    'mask_channel_prob': 0.0,\n",
       "    'mask_channel_length': 64,\n",
       "    'ema_local_encoder': False,\n",
       "    'local_grad_mult': 1.0,\n",
       "    'use_alibi_encoder': False,\n",
       "    'alibi_scale': 1.0,\n",
       "    'learned_alibi': False,\n",
       "    'alibi_max_pos': None,\n",
       "    'learned_alibi_scale': False,\n",
       "    'learned_alibi_scale_per_head': False,\n",
       "    'learned_alibi_scale_per_layer': False,\n",
       "    'num_alibi_heads': 12,\n",
       "    'model_depth': 12,\n",
       "    'decoder': None,\n",
       "    'max_alibi_scale': 0.0,\n",
       "    'max_alibi_grad': 0.0,\n",
       "    'max_alibi_val': 0.0,\n",
       "    'extractor_mode': 'layer_norm',\n",
       "    'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]',\n",
       "    'conv_pos_width': 95,\n",
       "    'conv_pos_groups': 16,\n",
       "    'conv_pos_depth': 5,\n",
       "    'conv_pos_pre_ln': False,\n",
       "    'mlp_encoder': False,\n",
       "    'mlp_n_in': 320,\n",
       "    'mlp_dim': None,\n",
       "    'mlp_layers': 9},\n",
       "   'image': {'type': 'IMAGE',\n",
       "    'prenet_depth': 4,\n",
       "    'prenet_layerdrop': 0.0,\n",
       "    'prenet_dropout': 0.0,\n",
       "    'start_drop_path_rate': 0.0,\n",
       "    'end_drop_path_rate': 0.0,\n",
       "    'num_extra_tokens': 0,\n",
       "    'init_extra_token_zero': True,\n",
       "    'mask_noise_std': 0.01,\n",
       "    'mask_prob_min': None,\n",
       "    'mask_prob': 0.7,\n",
       "    'inverse_mask': False,\n",
       "    'mask_prob_adjust': 0.0,\n",
       "    'keep_masked_pct': 0.0,\n",
       "    'mask_length': 5,\n",
       "    'add_masks': False,\n",
       "    'remove_masks': False,\n",
       "    'mask_dropout': 0.0,\n",
       "    'encoder_zero_mask': True,\n",
       "    'mask_channel_prob': 0.0,\n",
       "    'mask_channel_length': 64,\n",
       "    'ema_local_encoder': False,\n",
       "    'local_grad_mult': 1.0,\n",
       "    'use_alibi_encoder': False,\n",
       "    'alibi_scale': 1.0,\n",
       "    'learned_alibi': False,\n",
       "    'alibi_max_pos': None,\n",
       "    'learned_alibi_scale': False,\n",
       "    'learned_alibi_scale_per_head': False,\n",
       "    'learned_alibi_scale_per_layer': False,\n",
       "    'num_alibi_heads': 12,\n",
       "    'model_depth': 12,\n",
       "    'decoder': None,\n",
       "    'max_alibi_scale': 0.0,\n",
       "    'max_alibi_grad': 0.0,\n",
       "    'max_alibi_val': 0.0,\n",
       "    'input_size': 224,\n",
       "    'in_chans': 3,\n",
       "    'patch_size': 16,\n",
       "    'embed_dim': 768,\n",
       "    'fix_masks': False,\n",
       "    'exact_mask_pct': False,\n",
       "    'unmask_focal': False,\n",
       "    'focal_length': 1,\n",
       "    'alibi_dims': 2,\n",
       "    'alibi_distance': 'manhattan',\n",
       "    'fixed_positions': True,\n",
       "    'conv_pos_cfg': None,\n",
       "    'transformer_decoder': False,\n",
       "    'enc_dec_transformer': False,\n",
       "    'conv_mae': False,\n",
       "    'conv_mae_multiscale': True,\n",
       "    'conv_mae_masking': True},\n",
       "   'text': {'type': 'TEXT',\n",
       "    'prenet_depth': 0,\n",
       "    'prenet_layerdrop': 0.0,\n",
       "    'prenet_dropout': 0.0,\n",
       "    'start_drop_path_rate': 0.0,\n",
       "    'end_drop_path_rate': 0.0,\n",
       "    'num_extra_tokens': 0,\n",
       "    'init_extra_token_zero': True,\n",
       "    'mask_noise_std': 0.01,\n",
       "    'mask_prob_min': None,\n",
       "    'mask_prob': 0.42,\n",
       "    'inverse_mask': False,\n",
       "    'mask_prob_adjust': 0.0,\n",
       "    'keep_masked_pct': 0.0,\n",
       "    'mask_length': 1,\n",
       "    'add_masks': False,\n",
       "    'remove_masks': False,\n",
       "    'mask_dropout': 0.0,\n",
       "    'encoder_zero_mask': True,\n",
       "    'mask_channel_prob': 0.0,\n",
       "    'mask_channel_length': 64,\n",
       "    'ema_local_encoder': False,\n",
       "    'local_grad_mult': 1.0,\n",
       "    'use_alibi_encoder': False,\n",
       "    'alibi_scale': 1.0,\n",
       "    'learned_alibi': False,\n",
       "    'alibi_max_pos': None,\n",
       "    'learned_alibi_scale': False,\n",
       "    'learned_alibi_scale_per_head': False,\n",
       "    'learned_alibi_scale_per_layer': False,\n",
       "    'num_alibi_heads': 12,\n",
       "    'model_depth': 12,\n",
       "    'decoder': {'decoder_dim': 768,\n",
       "     'decoder_groups': 1,\n",
       "     'decoder_kernel': 9,\n",
       "     'decoder_layers': 5,\n",
       "     'input_dropout': 0.1,\n",
       "     'add_positions_masked': False,\n",
       "     'add_positions_all': False,\n",
       "     'final_layer_norm': False,\n",
       "     'tanh_scale': 0.0,\n",
       "     'project_first_residual': False,\n",
       "     'decoder_residual': False,\n",
       "     'projection_layers': 2,\n",
       "     'projection_ratio': 2.0,\n",
       "     'residual_scale': 1.0,\n",
       "     'remove_residual_noise': False,\n",
       "     'post_residual_ln': False},\n",
       "    'max_alibi_scale': 0.0,\n",
       "    'max_alibi_grad': 0.0,\n",
       "    'max_alibi_val': 0.0,\n",
       "    'max_source_positions': 512,\n",
       "    'learned_pos': True,\n",
       "    'dropout': 0.1,\n",
       "    'no_scale_embedding': True,\n",
       "    'layernorm_embedding': True,\n",
       "    'no_token_positional_embeddings': False}},\n",
       "  'shared_decoder': None,\n",
       "  'min_target_var': 0.1,\n",
       "  'min_pred_var': 0.01,\n",
       "  'supported_modality': 'TEXT',\n",
       "  'mae_init': False,\n",
       "  'bert_init': True,\n",
       "  'seed': 1,\n",
       "  'skip_ema': False,\n",
       "  'cls_loss': 0.0,\n",
       "  'alt_cls_targets': False,\n",
       "  'recon_loss': 0.0,\n",
       "  'recon_dim': 0,\n",
       "  'd2v_loss': 1.0,\n",
       "  'qk_scale': None,\n",
       "  'cosine_attention': False,\n",
       "  'decoder_group': False},\n",
       " 'task': {'_name': 'masked_lm',\n",
       "  'data': '/fsx-wav2vec/abaevski/data/nlp/bookwiki_aml-full-mmap2-bin',\n",
       "  'sample_break_mode': 'none',\n",
       "  'tokens_per_sample': 512,\n",
       "  'mask_prob': 0.15,\n",
       "  'leave_unmasked_prob': 0.0,\n",
       "  'random_token_prob': 0.0,\n",
       "  'freq_weighted_replacement': False,\n",
       "  'mask_whole_words': False,\n",
       "  'mask_multiple_length': 1,\n",
       "  'mask_stdev': 0.0,\n",
       "  'shorten_method': 'none',\n",
       "  'shorten_data_split_list': '',\n",
       "  'seed': 1,\n",
       "  'include_target_tokens': True,\n",
       "  'include_index': True,\n",
       "  'skip_masking': True,\n",
       "  'd2v2_multi': True},\n",
       " 'criterion': {'_name': 'model',\n",
       "  'loss_weights': {},\n",
       "  'log_keys': ['ema_decay',\n",
       "   'target_var',\n",
       "   'pred_var',\n",
       "   'model_norm',\n",
       "   'ema_norm',\n",
       "   'masked_pct'],\n",
       "  'rescale': 1.0,\n",
       "  'can_sum': True,\n",
       "  'log_ppl': False},\n",
       " 'optimizer': {'_name': 'composite',\n",
       "  'groups': {'default': {'lr_float': 0.0002,\n",
       "    'optimizer': {'_name': 'adam',\n",
       "     'adam_betas': [0.9, 0.98],\n",
       "     'adam_eps': 1e-06,\n",
       "     'weight_decay': 0.01},\n",
       "    'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 4000}}},\n",
       "  'dynamic_groups': True},\n",
       " 'lr_scheduler': {'_name': 'pass_through'},\n",
       " 'scoring': None,\n",
       " 'bpe': None,\n",
       " 'tokenizer': None,\n",
       " 'ema': {'_name': None,\n",
       "  'store_ema': False,\n",
       "  'ema_decay': 0.9999,\n",
       "  'ema_start_update': 0,\n",
       "  'ema_seed_model': None,\n",
       "  'ema_update_freq': 1,\n",
       "  'ema_fp32': False},\n",
       " 'job_logging_cfg': {'version': 1,\n",
       "  'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}},\n",
       "  'handlers': {'console': {'class': 'logging.StreamHandler',\n",
       "    'formatter': 'simple',\n",
       "    'stream': 'ext://sys.stdout'},\n",
       "   'file': {'class': 'logging.FileHandler',\n",
       "    'formatter': 'simple',\n",
       "    'filename': 'hydra_train.log'}},\n",
       "  'root': {'level': 'INFO', 'handlers': ['console', 'file']},\n",
       "  'disable_existing_loggers': False}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['cfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['modality_encoders.TEXT.local_encoder.embed_tokens.weight', 'modality_encoders.TEXT.local_encoder.embed_positions.weight', 'modality_encoders.TEXT.local_encoder.layernorm_embedding.weight', 'modality_encoders.TEXT.local_encoder.layernorm_embedding.bias', 'modality_encoders.TEXT.decoder.blocks.0.0.weight', 'modality_encoders.TEXT.decoder.blocks.0.0.bias', 'modality_encoders.TEXT.decoder.blocks.1.0.weight', 'modality_encoders.TEXT.decoder.blocks.1.0.bias', 'modality_encoders.TEXT.decoder.blocks.2.0.weight', 'modality_encoders.TEXT.decoder.blocks.2.0.bias', 'modality_encoders.TEXT.decoder.blocks.3.0.weight', 'modality_encoders.TEXT.decoder.blocks.3.0.bias', 'modality_encoders.TEXT.decoder.blocks.4.0.weight', 'modality_encoders.TEXT.decoder.blocks.4.0.bias', 'modality_encoders.TEXT.decoder.proj.0.weight', 'modality_encoders.TEXT.decoder.proj.0.bias', 'modality_encoders.TEXT.decoder.proj.2.weight', 'modality_encoders.TEXT.decoder.proj.2.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', '_ema'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters_from_state_dict(state_dict):\n",
    "    total_params = 0\n",
    "    \n",
    "    def count_parameters(obj):\n",
    "        nonlocal total_params\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            total_params += torch.numel(obj)\n",
    "        elif isinstance(obj, dict):\n",
    "            for k in obj:\n",
    "                count_parameters(obj[k])\n",
    "    \n",
    "    count_parameters(state_dict)\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238016256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters_from_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('base_text_only_task.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = cfg['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_default = Data2VecMultiConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.merge(cfg_default, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_name', 'loss_beta', 'loss_scale', 'depth', 'start_drop_path_rate', 'end_drop_path_rate', 'num_heads', 'norm_eps', 'norm_affine', 'encoder_dropout', 'post_mlp_drop', 'attention_dropout', 'activation_dropout', 'dropout_input', 'layerdrop', 'embed_dim', 'mlp_ratio', 'layer_norm_first', 'average_top_k_layers', 'end_of_block_targets', 'clone_batch', 'layer_norm_target_layer', 'batch_norm_target_layer', 'instance_norm_target_layer', 'instance_norm_targets', 'layer_norm_targets', 'ema_decay', 'ema_same_dtype', 'log_norms', 'ema_end_decay', 'ema_anneal_end_step', 'ema_encoder_only', 'max_update', 'modalities', 'shared_decoder', 'min_target_var', 'min_pred_var', 'supported_modality', 'mae_init', 'seed', 'skip_ema', 'cls_loss', 'recon_loss', 'd2v_loss', 'decoder_group'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from fairseq.data import Dictionary\n",
    "import os\n",
    "Task = namedtuple('Task', 'source_dictionary')\n",
    "\n",
    "# Create an instance\n",
    "dictionary = Dictionary.load(os.path.join('../data', \"dict.txt\"))\n",
    "dummy_task = Task(source_dictionary=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=Dictionary.load(os.path.join('../data', \"dict.txt\"))\n",
    "d.add_symbol(\"<mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fairseq.data.dictionary.Dictionary at 0x305a888b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_task.source_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Data2VecMultiModel.build_model(cfg, task=dummy_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Data2VecMultiModel:\n\tsize mismatch for modality_encoders.TEXT.local_encoder.embed_tokens.weight: copying a param with shape torch.Size([50265, 768]) from checkpoint, the shape in current model is torch.Size([50264, 768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CompSci/Uni/Projects/MasterThesis/src/fairseq/fairseq/models/fairseq_model.py:128\u001b[0m, in \u001b[0;36mBaseFairseqModel.load_state_dict\u001b[0;34m(self, state_dict, strict, model_cfg, args)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prune_state_dict\n\u001b[1;32m    127\u001b[0m new_state_dict \u001b[38;5;241m=\u001b[39m prune_state_dict(state_dict, model_cfg)\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mmrl/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Data2VecMultiModel:\n\tsize mismatch for modality_encoders.TEXT.local_encoder.embed_tokens.weight: copying a param with shape torch.Size([50265, 768]) from checkpoint, the shape in current model is torch.Size([50264, 768])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(state_dict['model'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
