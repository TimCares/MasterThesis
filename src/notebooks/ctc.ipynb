{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from torchaudio.models.decoder import ctc_decoder\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "\n",
    "from src.datasets.unimodal import get_raw_librispeech_dataset, RawLibriLightDataset, RawLibrispeechDataset\n",
    "from config import DATA_PATH\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/wer-scoring/lexicon-lower.txt', 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "with open('../../data/wer-scoring/lexicon.txt', 'w') as file:\n",
    "    for line in lines:\n",
    "        # Modify the line here as needed\n",
    "        modified_line = line.upper()  # Example modification\n",
    "        file.write(modified_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZIONISTS Z I O N I S T S |'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_raw_librispeech_dataset(dataset=\"dev-clean\", batch_size=1, shuffle=False, num_workers=1, normalize_waveform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_10M\n",
    "acoustic_model = bundle.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '|', 'e', 't', 'a', 'o', 'n', 'i', 'h', 's', 'r', 'd', 'l', 'u', 'm', 'w', 'c', 'f', 'g', 'y', 'p', 'b', 'v', 'k', \"'\", 'x', 'j', 'q', 'z']\n"
     ]
    }
   ],
   "source": [
    "tokens = [label.lower() for label in bundle.get_labels()]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 15:33:37,518 - torchaudio.utils.download - INFO - The local file (/Users/timcares/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lexicon.txt) exists. Skipping the download.\n",
      "2024-03-05 15:33:37,519 - torchaudio.utils.download - INFO - The local file (/Users/timcares/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/tokens.txt) exists. Skipping the download.\n",
      "2024-03-05 15:33:37,519 - torchaudio.utils.download - INFO - The local file (/Users/timcares/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lm.bin) exists. Skipping the download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PretrainedFiles(lexicon='/Users/timcares/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lexicon.txt', tokens='/Users/timcares/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/tokens.txt', lm='/Users/timcares/.cache/torch/hub/torchaudio/decoder-assets/librispeech-4-gram/lm.bin')\n"
     ]
    }
   ],
   "source": [
    "from torchaudio.models.decoder import download_pretrained_files\n",
    "\n",
    "files = download_pretrained_files(\"librispeech-4-gram\")\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm weight and word score after https://arxiv.org/pdf/2006.11477.pdf#page10 Appendix B\n",
    "# beam size after https://arxiv.org/pdf/2006.11477.pdf#page10 Section 4.4\n",
    "LM_WEIGHT = 2.90\n",
    "WORD_SCORE = -1.62\n",
    "BEAM_SIZE = 1500\n",
    "\n",
    "beam_search_decoder = ctc_decoder(\n",
    "    lexicon=files.lexicon,\n",
    "    tokens=files.tokens,\n",
    "    lm=files.lm,\n",
    "    beam_size=BEAM_SIZE,\n",
    "    lm_weight=LM_WEIGHT,\n",
    "    word_score=WORD_SCORE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = LIBRISPEECH(root=DATA_PATH, url='dev-clean', download=True)\n",
    "data_raw_iter = iter(data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2703 [00:16<1:14:38,  1.66s/it]"
     ]
    }
   ],
   "source": [
    "avg_wear = 0\n",
    "i=0\n",
    "for batch, padding_mask in tqdm(dataset_iter, total=len(dataset_iter)):\n",
    "    lengths = (1-padding_mask).sum(axis=-1)\n",
    "    emissions, output_lengths = acoustic_model(batch, lengths=lengths)\n",
    "    beam_search_result = beam_search_decoder(emissions, lengths=output_lengths)\n",
    "    for beam_result in beam_search_result:\n",
    "        actual_transcript = next(data_raw_iter)[2].lower().split()\n",
    "        wer = torchaudio.functional.edit_distance(actual_transcript, beam_result[0].words) / len(actual_transcript)\n",
    "        avg_wear += wer\n",
    "        i+=1\n",
    "avg_wear = avg_wear / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11764705882352941"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_wear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # batch wise\n",
    "\n",
    "# avg_wear = 0\n",
    "# for batch, padding_mask in tqdm(dataset_iter, total=len(dataset_iter)):\n",
    "#     lengths = (1-padding_mask).sum(axis=-1)\n",
    "#     emissions, output_lengths = acoustic_model(batch, lengths=lengths)\n",
    "#     beam_search_result = beam_search_decoder(emissions, lengths=output_lengths)\n",
    "#     for beam_result in beam_search_result:\n",
    "#         actual_transcript = next(data_raw_iter)[2].lower().split()\n",
    "#         wer = torchaudio.functional.edit_distance(actual_transcript, beam_result[0].words) / len(actual_transcript)\n",
    "#         print(beam_result[0].words)\n",
    "#         print(actual_transcript)\n",
    "#         avg_wear += wer\n",
    "#     break\n",
    "# avg_wear = avg_wear / (len(dataset_iter)*dataset.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
