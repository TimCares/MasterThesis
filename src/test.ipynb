{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timcares/miniforge3/envs/mmrl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchtext\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import config\n",
    "from config import DATA_PATH\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from datamodules import IMDBDataModule, CIFARDataModule, LibriSpeechDataModule, SpeechCommandsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = IMDBDataModule(data_path=DATA_PATH,\n",
    "                    batch_size=32,\n",
    "                    num_workers=5,\n",
    "                    num_max_bpe_tokens=512,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists. Skip creating it.\n",
      "Data already exists. Skip creating it.\n"
     ]
    }
   ],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 25000 text examples.\n"
     ]
    }
   ],
   "source": [
    "ds.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['language_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EnWik9Dataset(data_path=DATA_PATH,\n",
    "                   batch_size=32,\n",
    "                   num_workers=10,\n",
    "                   num_max_bpe_tokens=512,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CIFARDataModule(data_path=DATA_PATH,\n",
    "                    batch_size=32,\n",
    "                    num_workers=5,\n",
    "                    type='cifar10',\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LibriSpeechDataModule(data_path=DATA_PATH,\n",
    "                    sample_rate=16000,\n",
    "                    max_sample_size=320000,\n",
    "                    min_sample_size=32000,\n",
    "                    precompute_mask_config={\n",
    "                        'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]'\n",
    "                    },\n",
    "                    type='train-clean-100',\n",
    "                    batch_size=32,\n",
    "                    num_workers=4,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': tensor([13739, 23679, 15584,  2842, 16770, 10733, 24544, 25857, 20602, 27968,\n",
       "           586,  7061,  1678,  3295, 11294, 25649, 22392, 25551,  1222, 17027,\n",
       "         16134, 14407, 12839,  8639,  4447, 16349,  3390,  1536, 16905, 10352,\n",
       "         20260,  9649]),\n",
       " 'audio': tensor([[ 0.1434,  0.1970,  0.2531,  ...,  0.8795,  0.7710,  0.7199],\n",
       "         [ 0.5050,  0.7065,  0.8682,  ...,  0.0447,  0.0440,  0.0526],\n",
       "         [ 2.0687,  2.8521,  1.8890,  ..., -0.0058, -0.0086, -0.0091],\n",
       "         ...,\n",
       "         [ 2.6879,  2.8653,  2.8942,  ..., -0.0086, -0.1261, -0.2539],\n",
       "         [ 0.9282,  0.8093,  0.9436,  ...,  0.9603,  0.8756,  0.7874],\n",
       "         [ 0.4045, -0.7784, -1.6616,  ...,  0.1505, -0.0950, -0.4152]]),\n",
       " 'precomputed_mask': tensor([[1., 0., 0.,  ..., 1., 1., 0.],\n",
       "         [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 0.,  ..., 1., 0., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 1., 1.],\n",
       "         [1., 1., 0.,  ..., 0., 1., 1.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SpeechCommandsDataModule(data_path=DATA_PATH,\n",
    "                              feature_encoder_spec='[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]',\n",
    "                              batch_size=32,\n",
    "                              num_workers=5,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': tensor([[ 9.1553e-05,  1.2207e-04,  1.5259e-04,  ...,  6.1035e-05,\n",
       "           6.1035e-05,  6.1035e-05],\n",
       "         [ 2.1057e-03,  3.8757e-03,  5.0659e-03,  ..., -7.0496e-03,\n",
       "          -6.8665e-03, -5.3101e-03],\n",
       "         [-5.4932e-04, -7.0190e-04, -4.2725e-04,  ...,  0.0000e+00,\n",
       "          -9.1553e-05, -1.2207e-04],\n",
       "         ...,\n",
       "         [ 3.0518e-05, -9.1553e-05, -9.1553e-05,  ...,  3.0518e-05,\n",
       "          -3.0518e-05, -1.2207e-04],\n",
       "         [ 0.0000e+00, -6.1035e-05, -9.1553e-05,  ..., -3.0518e-05,\n",
       "           3.3569e-04,  6.7139e-04],\n",
       "         [ 4.2725e-04,  7.6294e-04,  1.1292e-03,  ..., -5.6366e-02,\n",
       "          -6.3782e-02, -6.4484e-02]]),\n",
       " 'label': tensor([29, 17,  8, 22, 13,  3,  6, 27, 26,  8, 29, 23, 16,  1,  1,  4, 28, 21,\n",
       "         14, 22, 19, 16, 20, 20, 10, 30, 10, 13, 12, 10,  4,  8]),\n",
       " 'id': tensor([79817, 58067, 25032, 74100, 35973, 69012,  1448,  8023, 27665, 25367,\n",
       "         79131, 75755, 66392, 12484, 12545,   798, 59311, 54927, 32393, 73040,\n",
       "          3562, 67160, 83693, 82767, 41652, 45952, 40463, 38482, 17602, 39058,\n",
       "          1247, 23137]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
