{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timcares/miniforge3/envs/mmrl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchtext\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import config\n",
    "from config import DATA_PATH\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from datamodules import IMDBDataModule, CIFARDataModule, LibriSpeechDataModule, SpeechCommandsDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = IMDBDataModule(data_path=DATA_PATH,\n",
    "                    batch_size=32,\n",
    "                    num_workers=5,\n",
    "                    num_max_bpe_tokens=512,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists. Skip creating it.\n",
      "Data already exists. Skip creating it.\n"
     ]
    }
   ],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 25000 text examples.\n"
     ]
    }
   ],
   "source": [
    "ds.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['language_tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EnWik9Dataset(data_path=DATA_PATH,\n",
    "                   batch_size=32,\n",
    "                   num_workers=10,\n",
    "                   num_max_bpe_tokens=512,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CIFARDataModule(data_path=DATA_PATH,\n",
    "                    batch_size=32,\n",
    "                    num_workers=5,\n",
    "                    type='cifar10',\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LibriSpeechDataModule(data_path=DATA_PATH,\n",
    "                    sample_rate=16000,\n",
    "                    max_sample_size=320000,\n",
    "                    min_sample_size=32000,\n",
    "                    precompute_mask_config={\n",
    "                        'feature_encoder_spec': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]'\n",
    "                    },\n",
    "                    type='train-clean-100',\n",
    "                    batch_size=32,\n",
    "                    num_workers=4,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': tensor([13739, 23679, 15584,  2842, 16770, 10733, 24544, 25857, 20602, 27968,\n",
       "           586,  7061,  1678,  3295, 11294, 25649, 22392, 25551,  1222, 17027,\n",
       "         16134, 14407, 12839,  8639,  4447, 16349,  3390,  1536, 16905, 10352,\n",
       "         20260,  9649]),\n",
       " 'audio': tensor([[ 0.1434,  0.1970,  0.2531,  ...,  0.8795,  0.7710,  0.7199],\n",
       "         [ 0.5050,  0.7065,  0.8682,  ...,  0.0447,  0.0440,  0.0526],\n",
       "         [ 2.0687,  2.8521,  1.8890,  ..., -0.0058, -0.0086, -0.0091],\n",
       "         ...,\n",
       "         [ 2.6879,  2.8653,  2.8942,  ..., -0.0086, -0.1261, -0.2539],\n",
       "         [ 0.9282,  0.8093,  0.9436,  ...,  0.9603,  0.8756,  0.7874],\n",
       "         [ 0.4045, -0.7784, -1.6616,  ...,  0.1505, -0.0950, -0.4152]]),\n",
       " 'precomputed_mask': tensor([[1., 0., 0.,  ..., 1., 1., 0.],\n",
       "         [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 0.,  ..., 1., 0., 1.],\n",
       "         [1., 1., 1.,  ..., 0., 1., 1.],\n",
       "         [1., 1., 0.,  ..., 0., 1., 1.]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SpeechCommandsDataModule(data_path=DATA_PATH,\n",
    "                              feature_encoder_spec='[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]',\n",
    "                              batch_size=32,\n",
    "                              num_workers=5,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': tensor([[ 9.1553e-05,  1.2207e-04,  1.5259e-04,  ...,  6.1035e-05,\n",
       "           6.1035e-05,  6.1035e-05],\n",
       "         [ 2.1057e-03,  3.8757e-03,  5.0659e-03,  ..., -7.0496e-03,\n",
       "          -6.8665e-03, -5.3101e-03],\n",
       "         [-5.4932e-04, -7.0190e-04, -4.2725e-04,  ...,  0.0000e+00,\n",
       "          -9.1553e-05, -1.2207e-04],\n",
       "         ...,\n",
       "         [ 3.0518e-05, -9.1553e-05, -9.1553e-05,  ...,  3.0518e-05,\n",
       "          -3.0518e-05, -1.2207e-04],\n",
       "         [ 0.0000e+00, -6.1035e-05, -9.1553e-05,  ..., -3.0518e-05,\n",
       "           3.3569e-04,  6.7139e-04],\n",
       "         [ 4.2725e-04,  7.6294e-04,  1.1292e-03,  ..., -5.6366e-02,\n",
       "          -6.3782e-02, -6.4484e-02]]),\n",
       " 'label': tensor([29, 17,  8, 22, 13,  3,  6, 27, 26,  8, 29, 23, 16,  1,  1,  4, 28, 21,\n",
       "         14, 22, 19, 16, 20, 20, 10, 30, 10, 13, 12, 10,  4,  8]),\n",
       " 'id': tensor([79817, 58067, 25032, 74100, 35973, 69012,  1448,  8023, 27665, 25367,\n",
       "         79131, 75755, 66392, 12484, 12545,   798, 59311, 54927, 32393, 73040,\n",
       "          3562, 67160, 83693, 82767, 41652, 45952, 40463, 38482, 17602, 39058,\n",
       "          1247, 23137]),\n",
       " 'padding_mask': tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_max_bpe_tokens=512\n",
    "from rich.progress import track\n",
    "from data_utils import get_bpe_encoder\n",
    "from fairseq.data import Dictionary\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from data import openai_imagenet_template, imagenet_classnames\n",
    "import os\n",
    "import torch\n",
    "tokenizer = get_bpe_encoder('../data')\n",
    "dictionary = Dictionary.load(os.path.join('../data', \"dict.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f79d200b694d4c8fcbc4f71ee95ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeroshot_weights = []\n",
    "for classname in track(imagenet_classnames, description=\"Building classifier\"):\n",
    "    texts = tokenizer.encode_lines(\n",
    "        [template(classname) for template in openai_imagenet_template],\n",
    "        tokens_per_sample=num_max_bpe_tokens-2,\n",
    "        to_tensor=False,\n",
    "    )\n",
    "    padding_masks = []\n",
    "    for i in range(len(texts)):\n",
    "        texts[i] = [dictionary.bos()] + texts[i] + [dictionary.eos()]\n",
    "        length = len(texts[i])\n",
    "        texts[i] = texts[i] + [dictionary.pad()] * (num_max_bpe_tokens - length)\n",
    "        padding_mask = [0] * length + [1] * (num_max_bpe_tokens - length)\n",
    "        padding_masks.append(padding_mask)\n",
    "\n",
    "    texts = torch.tensor(texts, dtype=torch.long)\n",
    "    padding_masks = torch.tensor(padding_masks, dtype=torch.long)\n",
    "    assert texts.size(1) == num_max_bpe_tokens\n",
    "    assert padding_masks.size(1) == num_max_bpe_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_dir_path = \"../data/language\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenWebTextDataset: Found 0 tar files, inflating...\n",
      "OpenWebTextDataset: Inflated all tar files.\n",
      "OpenWebTextDataset: Cleaning...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(nlp_dir_path, 'openwebtext')\n",
    "pattern = os.path.join(nlp_dir_path, '*.tar')\n",
    "files = glob.glob(pattern)\n",
    "print(f\"OpenWebTextDataset: Found {len(files)} tar files, inflating...\")\n",
    "for file in files:\n",
    "    os.system(f\"tar -xf {file} -C {nlp_dir_path}\")\n",
    "    os.remove(file)\n",
    "pattern = os.path.join(dataset_path, '*.xz')\n",
    "files = glob.glob(pattern)\n",
    "for file in files:\n",
    "    os.system(f\"unxz {file}\")\n",
    "print(\"OpenWebTextDataset: Inflated all tar files.\")\n",
    "\n",
    "pattern = rb'\\x00+'\n",
    "\n",
    "print(\"OpenWebTextDataset: Cleaning...\")\n",
    "files = os.listdir(dataset_path)\n",
    "for file in files:\n",
    "    with open(os.path.join(dataset_path, file), 'rb') as f:\n",
    "        first_line = f.readline()\n",
    "        rest_of_file = f.read()\n",
    "    \n",
    "    matches = list(re.finditer(pattern, first_line))\n",
    "    if matches:\n",
    "        first_line = first_line[matches[-1].end():]\n",
    "\n",
    "    with open(os.path.join(dataset_path, file), 'wb') as f:\n",
    "        f.write(first_line)\n",
    "        f.write(rest_of_file)\n",
    "\n",
    "    with open(os.path.join(dataset_path, file), 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    with open(os.path.join(dataset_path, file), 'w', encoding='utf-8') as f:\n",
    "        for line in lines:\n",
    "            stripped_line = line.strip()\n",
    "            if stripped_line != '' and stripped_line != '---':\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenWebTextDataset: Joining...\n"
     ]
    }
   ],
   "source": [
    "print(\"OpenWebTextDataset: Joining...\")\n",
    "with open(os.path.join(dataset_path, 'openwebtext.txt'), 'w') as f:\n",
    "    for file in files:\n",
    "        path_to_file = os.path.join(dataset_path, file)\n",
    "        with open(path_to_file, 'r') as f2:\n",
    "            f.write(f2.read())\n",
    "        os.remove(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = os.path.join(dataset_path, 'openwebtext.txt')\n",
    "out_file = os.path.join(dataset_path, 'openwebtext.bpe')\n",
    "encode(f'../data/encoder.json', f'../data/vocab.bpe', [in_file], [out_file], keep_empty=True)\n",
    "os.remove(in_file)\n",
    "process = ['fairseq-preprocess', '--only-source', '--srcdict', f'../data/dict.txt',\n",
    "            '--trainpref', out_file, '--destdir', f'{dataset_path}', '--workers', f'{os.cpu_count()}']\n",
    "subprocess.run(process)\n",
    "os.remove(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
