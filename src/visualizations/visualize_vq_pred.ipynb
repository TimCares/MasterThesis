{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-24 23:39:35,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:473: UserWarning: Overwriting beit_base_patch16_224 in registry with modeling_finetune.beit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_base_patch16_224(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:494: UserWarning: Overwriting beit_base_patch16_384 in registry with modeling_finetune.beit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_base_patch16_384(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:510: UserWarning: Overwriting beit_large_patch16_224 in registry with modeling_finetune.beit_large_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_large_patch16_224(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:519: UserWarning: Overwriting beit_large_patch16_384 in registry with modeling_finetune.beit_large_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_large_patch16_384(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:528: UserWarning: Overwriting beit_large_patch16_512 in registry with modeling_finetune.beit_large_patch16_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_large_patch16_512(pretrained=False, **kwargs):\n",
      "2024-09-24 23:39:36 | INFO | datasets | PyTorch version 2.2.0 available.\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:473: UserWarning: Overwriting beit_base_patch16_224 in registry with beit2.modeling_finetune.beit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_base_patch16_224(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:486: UserWarning: Overwriting beit_base_patch16_256 in registry with beit2.modeling_finetune.beit_base_patch16_256. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_base_patch16_256(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:494: UserWarning: Overwriting beit_base_patch16_384 in registry with beit2.modeling_finetune.beit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_base_patch16_384(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:502: UserWarning: Overwriting beit_24x544_patch16_224 in registry with beit2.modeling_finetune.beit_24x544_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_24x544_patch16_224(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:510: UserWarning: Overwriting beit_large_patch16_224 in registry with beit2.modeling_finetune.beit_large_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_large_patch16_224(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:519: UserWarning: Overwriting beit_large_patch16_384 in registry with beit2.modeling_finetune.beit_large_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_large_patch16_384(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:528: UserWarning: Overwriting beit_large_patch16_512 in registry with beit2.modeling_finetune.beit_large_patch16_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_large_patch16_512(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:536: UserWarning: Overwriting beit_huge_patch14_224 in registry with beit2.modeling_finetune.beit_huge_patch14_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_huge_patch14_224(pretrained=False, **kwargs):\n",
      "/root/MasterThesis/src/visualizations/../beit2/modeling_finetune.py:544: UserWarning: Overwriting beit_giant_patch14_224 in registry with beit2.modeling_finetune.beit_giant_patch14_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def beit_giant_patch14_224(pretrained=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../beit2')\n",
    "from datamodules import DATAMODULE_REGISTRY\n",
    "from models import MODEL_REGISTRY\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "from rich.progress import track\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer\n",
    "import textwrap\n",
    "plt.rcParams[\"axes.axisbelow\"] = False\n",
    "matplotlib.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_cluster_examples(model, dataloader, device):\n",
    "    cluster_mapping = dict()\n",
    "\n",
    "    for batch in track(dataloader):\n",
    "        image = batch['image'].to(device)\n",
    "        pred = model.quantize_image(image)['encoding_scores'].argmax(dim=-1)\n",
    "        pred = pred.cpu().tolist()\n",
    "        for i, cluster in enumerate(pred):\n",
    "            if cluster not in cluster_mapping:\n",
    "                cluster_mapping[cluster] = []\n",
    "            cluster_mapping[cluster].append(batch['image_raw'][i])\n",
    "\n",
    "    return cluster_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_text(figure, axes, text):\n",
    "    bbox = axes.get_position()\n",
    "    fig_width_inch = figure.get_size_inches()[0]\n",
    "    axes_width_inch = bbox.width * fig_width_inch\n",
    "    char_width_inch = 0.1\n",
    "    max_chars_per_line = int(axes_width_inch / char_width_inch)\n",
    "    wrapped_text = \"\\n\".join(textwrap.wrap(text, width=max_chars_per_line))\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_ticks(axes):\n",
    "    axes.set_xticks([])\n",
    "    axes.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_membership(batch, model, cluster_mapping, device):\n",
    "    n_cluster_examples = 5\n",
    "    num_cols = n_cluster_examples+2\n",
    "    num_rows = batch.shape[0]\n",
    "\n",
    "    image = batch['image'].to(device)\n",
    "    pred = model.quantize_image(image)['encoding_scores'].argmax(dim=-1)\n",
    "    pred = pred.cpu().tolist()\n",
    "\n",
    "    captions = tokenizer.batch_decode(batch['text'], skip_special_tokens=True)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 2.5*num_rows))\n",
    "\n",
    "    axes[0, 0].set_title(\"Caption\", fontsize=18, fontweight='bold', fontname='DejaVu Serif')\n",
    "    axes[0, 1].set_title(\"Image\", fontsize=18, fontweight='bold', fontname='DejaVu Serif')\n",
    "    for r_idx, j in enumerate(range(2, num_cols), start=1):\n",
    "        axes[0, j].set_title(f\"Member {r_idx}\", fontsize=18, fontweight='bold', fontname='DejaVu Serif')\n",
    "\n",
    "    for i, caption in enumerate(captions):\n",
    "        axes[i, 0].text(0.5, 0.5, fit_text(caption), ha='center', va='center', fontsize=12)\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 1].imshow(batch['image_raw'][i].permute(1, 2, 0))\n",
    "        disable_ticks(axes[i, 1])\n",
    "        for spine in axes[i, 1].spines.values():\n",
    "            spine.set_edgecolor(\"black\")\n",
    "            spine.set_linewidth(1)\n",
    "\n",
    "        pred_cluster_idx = pred[i]\n",
    "\n",
    "        for j, cluster in enumerate(cluster_mapping[pred_cluster_idx][:n_cluster_examples], start=2):\n",
    "            axes[i, j].imshow(cluster.permute(1, 2, 0))\n",
    "            disable_ticks(axes[i, j])\n",
    "            for spine in axes[i, j].spines.values():\n",
    "                spine.set_edgecolor(\"black\")\n",
    "                spine.set_linewidth(1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.image_vq import ImageVQ, ImageVQLightningModule\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model:ImageVQ = ImageVQLightningModule.load_from_checkpoint(\"/workspace/models/image_vq_8/model-20016-0.1535-train.ckpt\", strict=False).model\n",
    "model = model.to(device)\n",
    "model.requires_grad_(False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_args = {\n",
    "    'data_path': '/workspace',\n",
    "    'pretraining': True,\n",
    "    'batch_size':256,\n",
    "    'num_workers':5,\n",
    "    'shuffle':False,\n",
    "    'drop_last':False,\n",
    "}\n",
    "imagenet = DATAMODULE_REGISTRY['imagenet'](**imagenet_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet.prepare_data()\n",
    "imagenet.setup('fit')\n",
    "dl_imagenet = imagenet.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mapping = get_cluster_examples(model, dl_imagenet, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imagenet, dl_imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dm_kwargs = {\n",
    "    'data_path': '/workspace',\n",
    "    'num_max_bpe_tokens': 64,\n",
    "    'color_jitter': None,\n",
    "    'beit_transforms': False,\n",
    "    'crop_scale': [1.0, 1.0],\n",
    "    'batch_size': 20,\n",
    "    'num_workers': 2,\n",
    "    'shuffle': True,\n",
    "    'drop_last': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "coco_dm = DATAMODULE_REGISTRY['coco_captions'](**coco_dm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 23:39:38 | INFO | datasets_.base_datasets | [COCOCaptions]: Data already exists under: /workspace/coco\n",
      "2024-09-24 23:39:38 | INFO | datasets_.base_datasets | [COCOCaptions]: Data already exists under: /workspace/coco\n",
      "2024-09-24 23:39:39 | INFO | datasets_.base_datasets | [COCOCaptions]: Data already exists under: /workspace/coco\n",
      "2024-09-24 23:39:39 | INFO | datasets_.base_datasets | [COCOCaptions]: Load 25010 image-text pairs from /workspace/coco/coco_captioning.test.jsonl. \n"
     ]
    }
   ],
   "source": [
    "coco_dm.prepare_data()\n",
    "coco_dm.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = coco_dm.test_dataloader()\n",
    "dl_iter = iter(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dl_iter)\n",
    "plot_cluster_membership(batch, model, cluster_mapping, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
