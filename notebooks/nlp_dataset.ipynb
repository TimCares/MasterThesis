{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timcares/miniforge3/envs/mmrl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../src/fairseq')\n",
    "sys.path.append('../src/fairseq/examples')\n",
    "from src.unimodal import NLPDataset, AudioDataset\n",
    "from fairseq.tasks.audio_pretraining import AudioMaskingConfig\n",
    "from dataclasses import asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/language/enwik9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 2 blocks from: ../data/language/enwik9/train\n"
     ]
    }
   ],
   "source": [
    "ds = NLPDataset(data_path=data_path, num_max_bpe_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ds.get_dataloader(batch_size=8, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('source',\n",
       "              tensor([[    0, 32098,  3443,  ...,     1,     1,     1],\n",
       "                      [    0,   260, 13161,  ...,   548,  8624,     2]])),\n",
       "             ('padding_mask',\n",
       "              tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "                      [False, False, False,  ..., False, False, False]]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(loader_iter)['net_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '../data/LibriSpeech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_cfg =  AudioMaskingConfig(\n",
    "    feature_encoder_spec='[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]',\n",
    "    mask_prob=0.5,\n",
    "    mask_prob_adjust=0.05,\n",
    "    mask_length=5,\n",
    "    inverse_mask=False,\n",
    "    mask_dropout=0,\n",
    "    clone_batch=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset = AudioDataset(data_path=audio_path, sample_rate=16000, max_sample_size=320000, min_sample_size=32000, precompute_mask_config=asdict(am_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_loader = audio_dataset.get_dataloader(batch_size=8, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_loader_iter = iter(audio_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 84080])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(audio_loader_iter)['net_input']['source'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': tensor([15551,  3939,  3716, 25035, 11659, 27998, 22352,  2101]),\n",
       " 'net_input': {'source': tensor([[ 9.0226e-01,  8.9310e-01,  8.4690e-01,  ...,  2.1881e+00,\n",
       "            2.1682e+00,  2.3574e+00],\n",
       "          [ 4.9034e-01, -2.5139e-01, -2.2811e-02,  ..., -4.8209e-02,\n",
       "           -4.6906e-02, -1.6738e-01],\n",
       "          [-4.1562e-01, -5.9688e-01, -6.0068e-01,  ...,  1.2183e-01,\n",
       "            1.6974e+00,  2.6506e+00],\n",
       "          ...,\n",
       "          [-3.7082e-03, -3.1989e-03, -2.6895e-03,  ...,  3.9766e-01,\n",
       "            4.1854e-01,  4.0530e-01],\n",
       "          [-1.2794e-01, -9.9036e-02, -5.5682e-02,  ..., -1.3812e+00,\n",
       "           -1.8875e+00, -2.6442e+00],\n",
       "          [-9.4794e-04, -9.4794e-04, -9.4794e-04,  ..., -9.4794e-04,\n",
       "           -9.4794e-04, -9.4794e-04]]),\n",
       "  'precomputed_mask': tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 1., 1.,  ..., 0., 0., 0.]])}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(audio_loader_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
