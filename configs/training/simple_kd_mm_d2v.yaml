# @package _group_

model:
  pretrained_path: ../models
  pretrained:
    audio: base_libri.pt
    image: base_imagenet.pt
    text: nlp_base.pt

  encoders_embed_dim: 768
  embed_dim: 768
  depth: 5
  num_heads: 12 
  mlp_ratio: 4.0
  encoder_dropout: 0.1
  attention_dropout: 0.1
  activation_dropout: 0.1
  post_mlp_drop: 0.1
  #norm_eps: 1e-6
  norm_affine: True
  layer_norm_first: False
  #loss_scale:
  dropout_input: 0.0
  start_drop_path_rate: 0
  end_drop_path_rate: 0
  layerdrop: 0.0

  end_of_block_targets: False

  modality_encoder_proj: False

num_updates:
val_frequency:

# following: state_dict['cfg']['model']
average_top_k_layers_teacher:
  audio: 8 # base_libri.pt
  image: 10 # base_imagenet.pt
  text: 12 # nlp_base.pt

average_top_k_layers_student: 

layer_norm_target_layer:
instance_norm_target_layer:
batch_norm_target_layer:

optimizer:
  params:

  schedule:
    warmup_steps:
    max_steps: ${training.num_updates}