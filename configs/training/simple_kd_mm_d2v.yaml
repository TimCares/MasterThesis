# @package _group_

hydra:
  run:
    dir: .


dry_run: True
data_path: ../data
model_path: ../models
seed: 42

load_checkpoint:

nlp_context_length: 256

model:
  pretrained_path: ${model_path}
  pretrained:
    audio: base_libri.pt
    image: base_imagenet.pt
    text: nlp_base.pt

  encoders_embed_dim: 768
  embed_dim: 768
  depth: 5
  num_heads: 12 
  mlp_ratio: 4.0
  encoder_dropout: 0.1
  attention_dropout: 0.1
  activation_dropout: 0.1
  post_mlp_drop: 0.1
  #norm_eps: 1e-6
  norm_affine: True
  layer_norm_first: False
  #loss_scale:
  dropout_input: 0.0
  start_drop_path_rate: 0
  end_drop_path_rate: 0
  layerdrop: 0.0

  end_of_block_targets: False

  modality_encoder_proj: False

  seed: ${seed}

data:
  # datasets/dataloaders must start with an underscore, the string after that is used as a key to the registries
  data_path: ${data_path}
  batch_size: 256
  num_workers: 5
  shuffle: False
  drop_last: False

  _openwebtext:
    num_max_bpe_tokens: ${nlp_context_length}
    sample_break_mode: none

  _imagenet:
    beit_transforms: False
    no_transform: False
    transform_jitter: False
    precompute_mask_config: 
    crop_scale: [0.6, 1]
    local_cache_path:

  _librispeech:
    sample_rate: 16000
    max_sample_size: 160000
    min_sample_size: 32000
    precompute_mask_config: 
    type_train: 
    type_test: 

zero_shot_val:
  n_neighbors: 100
  data_path: ${data_path}
  num_max_bpe_tokens: ${nlp_context_length}
  is_multimodal_aligned: False
  datamodules: # dataloder args are taken from top-level key "data"
    _imdb:
      data_path: ${data_path}
      num_max_bpe_tokens: ${nlp_context_length}
    _cifar10:
      data_path: ${data_path}
    _cifar100:
      data_path: ${data_path}
    _speechcommands:
      data_path: ${data_path}
      min_sample_size: 0 # take all samples
      normalize: True
      pad: True

checkpoint:
  dirpath: ${model_path}
  filename: mm-d2v-{step}-{${checkpoint.monitor}:.4f}
  save_last: True
  every_n_train_steps: ${lightning_trainer.val_check_interval}
  save_on_train_epoch_end: False # False -> run at end of validation
  verbose: True
  monitor: val/unimodal-imagenet-knn--zeroshot-top5-acc # logged in: ZeroShotCallback
  mode: max
  auto_insert_metric_name: False

# following: state_dict['cfg']['model']
average_top_k_layers_teacher:
  audio: 8 # base_libri.pt
  image: 10 # base_imagenet.pt
  text: 12 # nlp_base.pt

average_top_k_layers_student: ${model.depth}

layer_norm_target_layer: False
instance_norm_target_layer: True
batch_norm_target_layer: False

optimizer:
  params:

  schedule:
    warmup_steps: 500
    max_steps: ${lightning_trainer.max_steps}

lightning_trainer:
  devices: -1
  max_steps: 30000
  val_check_interval: 2000
  num_sanity_val_steps: 0 # mean test running "num_sanity_val_steps" batches of the validation dataloaders, but here we have no classical validation
  precision: 16-mixed